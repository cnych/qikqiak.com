<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>alertmanager on 阳明的博客</title>
    <link>https://www.qikqiak.com/tags/alertmanager/</link>
    <description>Recent content in alertmanager on 阳明的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 06 Mar 2022 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.qikqiak.com/tags/alertmanager/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Prometheus 监控 Kubernetes Job 资源误报的坑</title>
      <link>https://www.qikqiak.com/post/prometheus-monitor-k8s-job-trap/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-monitor-k8s-job-trap/</guid>
      <description>&lt;p&gt;昨天在 Prometheus 课程辅导群里面有同学提到一个问题，是关于 Prometheus 监控 Job 任务误报的问题，大概的意思就 CronJob 控制的 Job，前面执行失败了，监控会触发报警，解决后后面生成的新的 Job 可以正常执行了，但是还是会收到前面的报警：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://bxdc-static.oss-cn-beijing.aliyuncs.com/images/20220305200158.png&#34; alt=&#34;问题描述&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这是因为一般在执行 Job 任务的时候我们会保留一些历史记录方便排查问题，所以如果之前有失败的 Job 了，即便稍后会变成成功的，那么之前的 Job 也会继续存在，而大部分直接使用 kube-prometheus 安装部署的话使用的默认报警规则是&lt;code&gt;kube_job_status_failed &amp;gt; 0&lt;/code&gt;，这显然是不准确的，只有我们去手动删除之前这个失败的 Job 任务才可以消除误报，当然这种方式是可以解决问题的，但是不够自动化，一开始没有想得很深入，想去自动化删除失败的 Job 来解决，但是这也会给运维人员带来问题，就是不方便回头去排查问题。下面我们来重新整理下思路解决下这个问题。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>使用 Loki 进行日志监控和报警</title>
      <link>https://www.qikqiak.com/post/use-loki-monitor-alert/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/use-loki-monitor-alert/</guid>
      <description>&lt;p&gt;对于生产环境以及一个有追求的运维人员来说，哪怕是毫秒级别的宕机也是不能容忍的。对基础设施及应用进行适当的日志记录和监控非常有助于解决问题，还可以帮助优化成本和资源，以及帮助检测以后可能会发生的一些问题。前面我们介绍了使用 EFK 技术栈来收集和监控日志，本文我们将使用更加轻量级的 Grafana Loki 来实现日志的监控和报警，一般来说 Grafana Loki 包括3个主要的组件：Promtail、Loki 和 Grafana（简称 PLG），最为关键的是如果你熟悉使用 Prometheus 的话，对于 Loki 的使用也完全没问题，因为他们的使用方法基本一致的，如果是在 Kubernetes 集群中自动发现的还具有相同的 Label 标签。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AlertManager 何时报警</title>
      <link>https://www.qikqiak.com/post/alertmanager-when-alert/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/alertmanager-when-alert/</guid>
      <description>&lt;p&gt;在使用 Prometheus 进行监控的时候，通过 AlertManager 来进行告警，但是有很多人对报警的相关配置比较迷糊，不太清楚具体什么时候会进行告警。下面我们来简单介绍下 AlertManager 中的几个容易混淆的参数。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus Operator 自定义报警</title>
      <link>https://www.qikqiak.com/post/prometheus-operator-custom-alert/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-operator-custom-alert/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.qikqiak.com/post/prometheus-operator-monitor-etcd&#34;&gt;上篇文章我们介绍了如何自定义一个 ServiceMonitor 对象&lt;/a&gt;，但是如果需要自定义一个报警规则的话呢？又该怎么去做呢？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus报警AlertManager实战</title>
      <link>https://www.qikqiak.com/post/alertmanager-of-prometheus-in-practice/</link>
      <pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/alertmanager-of-prometheus-in-practice/</guid>
      <description>&lt;p&gt;在前面一文&lt;a href=&#34;https://www.qikqiak.com/post/kubernetes-monitor-prometheus-grafana/&#34;&gt;Kubernetes使用Prometheus搭建监控平台&lt;/a&gt;中我们知道了怎么使用&lt;code&gt;Prometheus&lt;/code&gt;来搭建监控平台，也了解了&lt;code&gt;grafana&lt;/code&gt;的使用。这篇文章就来说说报警系统的搭建，有人说报警用&lt;code&gt;grafana&lt;/code&gt;就行了，实际上&lt;code&gt;grafana&lt;/code&gt;对报警的支持真的很弱，而&lt;code&gt;Prometheus&lt;/code&gt;提供的报警系统就强大很多，今天我们的主角就是&lt;code&gt;AlertManager&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>