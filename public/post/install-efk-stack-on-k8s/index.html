<!DOCTYPE html>
<html lang="zh">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">


  <title>在 Kubernetes 上搭建 EFK 日志收集系统-www.qikqiak.com|阳明的博客|Kubernetes|Docker|istio|Python|Golang|Cloud Native</title>
  <meta property="og:title" content="在 Kubernetes 上搭建 EFK 日志收集系统" />
  <meta name="twitter:title" content="在 Kubernetes 上搭建 EFK 日志收集系统" />

  <meta name="description" content="上节课和大家介绍了 Kubernetes 集群中的几种日志收集方案，Kubernetes 中比较流行的日志收集解决方案是 Elasticsearch、Fluentd 和 Kibana（EFK）技术栈，也是官方现在比较推荐的一种方案。

Elasticsearch 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。

Elasticsearch 通常与 Kibana 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。

Fluentd是一个流行的开源数据收集器，我们将在 Kubernetes 集群节点上安装 Fluentd，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。">
  <meta property="og:description" content="上节课和大家介绍了 Kubernetes 集群中的几种日志收集方案，Kubernetes 中比较流行的日志收集解决方案是 Elasticsearch、Fluentd 和 Kibana（EFK）技术栈，也是官方现在比较推荐的一种方案。

Elasticsearch 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。

Elasticsearch 通常与 Kibana 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。

Fluentd是一个流行的开源数据收集器，我们将在 Kubernetes 集群节点上安装 Fluentd，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。">
  <meta name="twitter:description" content="上节课和大家介绍了 Kubernetes 集群中的几种日志收集方案，Kubernetes 中比较流行的日志收集解决方案是 Elasticsearch、Fluentd 和 Kibana（EFK）技术栈，也是官方现在比较推荐的一种方案。

Elasticsearch 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。 …">
  <meta name="author" content=""/>
  <link href='https://www.qikqiak.com/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta property="og:image" content="https://www.qikqiak.com/img/avatar.jpeg" />
  <meta name="twitter:image" content="https://www.qikqiak.com/img/avatar.jpeg" />
  <meta name="twitter:card" content="summary" />
  <meta property="og:url" content="https://www.qikqiak.com/post/install-efk-stack-on-k8s/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="阳明的博客" />

  <meta name="generator" content="Hugo 0.53" />
  <link rel="canonical" href="https://www.qikqiak.com/post/install-efk-stack-on-k8s/" />
  <link rel="alternate" href="https://www.qikqiak.com/index.xml" type="application/rss+xml" title="阳明的博客">

  
  
  <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700%7COpen+Sans:400,700" rel="stylesheet">
  

  <link rel="stylesheet" href='https://www.qikqiak.com/css/bundle.min.a4cfbddc97aac29b4539ae8497732cc269ac1cfa85e5e673da9eccb491700d8a.css' integrity='sha256-pM&#43;93JeqwptFOa6El3MswmmsHPqF5eZz2p7MtJFwDYo='>

  
    
    <!--[if lt IE 9]>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js"></script>
        <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
    <![endif]-->
<meta name="google-site-verification" content="oKxX4fOvB2yYmU02txZFChM93XQbESU4JaG3tNH9Hm8" />
<meta name="baidu-site-verification" content="F5ojAyqaKU" />
<meta name="keywords" content="kubernetes, log, EFK, Elasticsearch, Fluentd, Kibana">
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d611849735f187dd788dc054908f7d7a";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-69668147-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">切换导航</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://www.qikqiak.com/">阳明的博客</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="首页" href="https://www.qikqiak.com/">首页</a>
            </li>
          
        
          
            <li>
              <a title="Kubernetes" href="https://www.qikqiak.com/page/archive/">Kubernetes</a>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">文章分类</a>
              <div class="navlinks-children">
                
                  <a href="https://www.qikqiak.com/archives">Archive</a>
                
                  <a href="https://www.qikqiak.com/tags">tags</a>
                
                  <a href="https://www.qikqiak.com/tags/kubernetes">kubernetes</a>
                
                  <a href="https://www.qikqiak.com/tags/python">python</a>
                
                  <a href="https://www.qikqiak.com/tags/django">django</a>
                
                  <a href="https://www.qikqiak.com/tags/ops">devops</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" href="javascript:void(0)">项目</a>
              <div class="navlinks-children">
                
                  <a href="https://youdianzhishi.com/?utm_source=blog&amp;utm_campaign=referral&amp;utm_medium=topmenu">优点知识</a>
                
                  <a href="https://www.qikqiak.com/k8s-book/">k8s进阶手册</a>
                
                  <a href="https://www.qikqiak.com/istio-book/">一起学istio</a>
                
                  <a href="https://www.qikqiak.com/tdd-book/">Python微服务</a>
                
                  <a href="https://md.qikqiak.com/">Markdown微信</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="关于" href="https://www.qikqiak.com/page/about/">关于</a>
            </li>
          
        

        

        

        
          <li>
            <a href="#modalSearch" data-toggle="modal" data-target="#modalSearch" style="outline: none;">
              <span id="searchGlyph" class="glyphicon glyphicon-search"></span>
            </a>
          </li>
          

      </ul>
    </div>

  </div>
</nav>





  <div id="modalSearch" class="modal fade" role="dialog">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal">&times;</button>
          <h4 class="modal-title">搜索</h4>
        </div>
        <div class="modal-body">
            
<div class="aa-input-container" id="aa-input-container">
    <input type="search" id="aa-search-input" class="aa-input-search" placeholder="Search for titles or URIs..." name="search" autocomplete="off" />
    <svg class="aa-input-icon" viewBox="654 -372 1664 1664">
        <path d="M1806,332c0-123.3-43.8-228.8-131.5-316.5C1586.8-72.2,1481.3-116,1358-116s-228.8,43.8-316.5,131.5  C953.8,103.2,910,208.7,910,332s43.8,228.8,131.5,316.5C1129.2,736.2,1234.7,780,1358,780s228.8-43.8,316.5-131.5  C1762.2,560.8,1806,455.3,1806,332z M2318,1164c0,34.7-12.7,64.7-38,90s-55.3,38-90,38c-36,0-66-12.7-90-38l-343-342  c-119.3,82.7-252.3,124-399,124c-95.3,0-186.5-18.5-273.5-55.5s-162-87-225-150s-113-138-150-225S654,427.3,654,332  s18.5-186.5,55.5-273.5s87-162,150-225s138-113,225-150S1262.7-372,1358-372s186.5,18.5,273.5,55.5s162,87,225,150s113,138,150,225  S2062,236.7,2062,332c0,146.7-41.3,279.7-124,399l343,343C2305.7,1098.7,2318,1128.7,2318,1164z" />
    </svg>
</div>
<script src="https://www.qikqiak.com/js/algoliasearch.min.js"></script>
<script src="https://www.qikqiak.com/js/autocomplete.min.js"></script>

<script>
var client = algoliasearch("1JDRAS0AZR", "8804ac109158bb3bb60d74ce98fa332f");
var index = client.initIndex('prod_blog');

autocomplete('#aa-search-input',
{ hint: false}, {
    source: autocomplete.sources.hits(index, {hitsPerPage: 5}),
    
    displayKey: 'name',
    
    templates: {
        
        suggestion: function(suggestion) {
            return '<span>' + '<a href="https://www.qikqiak.com/post/' + suggestion.slug + '">' +
            suggestion._highlightResult.title.value + '</a></span>';
        }
    }
});
</script>
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-default" data-dismiss="modal">close</button>
        </div>
      </div>
    </div>
  </div>

    
  
  
  




  
    <div id="header-big-imgs" data-num-img=1 data-img-src-1="https://ws3.sinaimg.cn/large/006tNc79gy1fz9oz0m3kcj30zc0bmdhd.jpg" data-img-desc-1="EFK Stack"></div>
  

  <header class="header-section has-img">
    
      <div class="intro-header big-img">
        
        <div class="container">
          <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
              <div class="post-heading">
                <h1>在 Kubernetes 上搭建 EFK 日志收集系统</h1>
                  
                  
                    <span class="post-meta">
  发表于 January 17, 2019
  
</span>


                  
              </div>
            </div>
          </div>
        </div>
        <span class="img-desc" style="display: inline;"></span>
      </div>
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              <h1>在 Kubernetes 上搭建 EFK 日志收集系统</h1>
                
                
                  <span class="post-meta">
  发表于 January 17, 2019
  
</span>


                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

      <div>
          
          
          <h5 id="tags" style="margin-top: 0px;">标签:
            
                <a href="https://www.qikqiak.com/tags/kubernetes/">kubernetes</a> &nbsp;
            
                <a href="https://www.qikqiak.com/tags/efk/">EFK</a> &nbsp;
            
                <a href="https://www.qikqiak.com/tags/elasticsearch/">Elasticsearch</a> &nbsp;
            
                <a href="https://www.qikqiak.com/tags/fluentd/">Fluentd</a> &nbsp;
            
                <a href="https://www.qikqiak.com/tags/kibana/">Kibana</a> &nbsp;
            
          </h5>
          
      </div>

      <article role="main" class="blog-post" itemprop="articleBody" id="content">
        
          
<aside class="toc">
  <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#创建-elasticsearch-集群">创建 Elasticsearch 集群</a></li>
<li><a href="#创建-kibana-服务">创建 Kibana 服务</a></li>
<li><a href="#部署-fluentd">部署 Fluentd</a>
<ul>
<li><a href="#工作原理">工作原理</a></li>
<li><a href="#配置">配置</a>
<ul>
<li><a href="#日志源配置">日志源配置</a></li>
<li><a href="#路由配置">路由配置</a></li>
</ul></li>
<li><a href="#安装">安装</a></li>
<li><a href="#测试">测试</a></li>
</ul></li>
<li><a href="#推广">推广</a></li>
</ul></li>
</ul>
</nav>
</aside>

        

        
        
        

        
        
        

        
        

        <p><a href="https://www.qikqiak.com/post/kubernetes-logs-architecture/">上节课和大家介绍了 <code>Kubernetes</code> 集群中的几种日志收集方案</a>，Kubernetes 中比较流行的日志收集解决方案是 <code>Elasticsearch</code>、<code>Fluentd</code> 和 <code>Kibana</code>（EFK）技术栈，也是官方现在比较推荐的一种方案。</p>

<p><code>Elasticsearch</code> 是一个实时的、分布式的可扩展的搜索引擎，允许进行全文、结构化搜索，它通常用于索引和搜索大量日志数据，也可用于搜索许多不同类型的文档。</p>

<p>Elasticsearch 通常与 <code>Kibana</code> 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。</p>

<p><code>Fluentd</code>是一个流行的开源数据收集器，我们将在 Kubernetes 集群节点上安装 Fluentd，通过获取容器日志文件、过滤和转换日志数据，然后将数据传递到 Elasticsearch 集群，在该集群中对其进行索引和存储。</p>

<p>我们先来配置启动一个可扩展的 Elasticsearch 集群，然后在 Kubernetes 集群中创建一个 Kibana 应用，最后通过 DaemonSet 来运行 Fluentd，以便它在每个 Kubernetes 工作节点上都可以运行一个 Pod。</p>

<h2 id="创建-elasticsearch-集群">创建 Elasticsearch 集群</h2>

<p>在创建 Elasticsearch 集群之前，我们先创建一个命名空间，我们将在其中安装所有日志相关的资源对象。</p>

<p>新建一个 kube-logging.yaml 文件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: logging</code></pre></div>
<p>然后通过 kubectl 创建该资源清单，创建一个名为 logging 的 namespace：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f kube-logging.yaml
namespace/logging created
$ kubectl get ns
NAME           STATUS    AGE
default        Active    244d
istio-system   Active    100d
kube-ops       Active    179d
kube-public    Active    244d
kube-system    Active    244d
logging        Active    4h
monitoring     Active    35d</code></pre></div>
<p>现在创建了一个命名空间来存放我们的日志相关资源，接下来可以部署 EFK 相关组件，首先开始部署一个3节点的 Elasticsearch 集群。</p>

<p>这里我们使用3个 Elasticsearch Pod 来避免高可用下多节点集群中出现的“脑裂”问题，当一个或多个节点无法与其他节点通信时会产生“脑裂”，可能会出现几个主节点。</p>

<blockquote>
<p>了解更多 Elasticsearch 集群脑裂问题，可以查看文档<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain</a></p>
</blockquote>

<p>一个关键点是您应该设置参数<code>discover.zen.minimum_master_nodes=N/2+1</code>，其中<code>N</code>是 Elasticsearch 集群中符合主节点的节点数，比如我们这里3个节点，意味着<code>N</code>应该设置为2。这样，如果一个节点暂时与集群断开连接，则另外两个节点可以选择一个新的主节点，并且集群可以在最后一个节点尝试重新加入时继续运行，在扩展 Elasticsearch 集群时，一定要记住这个参数。</p>

<p>首先创建一个名为 elasticsearch 的无头服务，新建文件 elasticsearch-svc.yaml，文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">kind: Service
apiVersion: v1
metadata:
  name: elasticsearch
  namespace: logging
  labels:
    app: elasticsearch
spec:
  selector:
    app: elasticsearch
  clusterIP: None
  ports:
    - port: <span style="color:#bd93f9">9200</span>
      name: rest
    - port: <span style="color:#bd93f9">9300</span>
      name: inter-node</code></pre></div>
<p>定义了一个名为 elasticsearch 的 Service，指定标签<code>app=elasticsearch</code>，当我们将 Elasticsearch StatefulSet 与此服务关联时，服务将返回带有标签<code>app=elasticsearch</code>的 Elasticsearch Pods 的 DNS A 记录，然后设置<code>clusterIP=None</code>，将该服务设置成无头服务。最后，我们分别定义端口9200、9300，分别用于与 REST API 交互，以及用于节点间通信。</p>

<p>使用 kubectl 直接创建上面的服务资源对象：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f elasticsearch-svc.yaml
service/elasticsearch created
$ kubectl get services --namespace<span style="color:#ff79c6">=</span>logging
Output
NAME            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>             AGE
elasticsearch   ClusterIP   None         &lt;none&gt;        <span style="color:#bd93f9">9200</span>/TCP,9300/TCP   26s</code></pre></div>
<p>现在我们已经为 Pod 设置了无头服务和一个稳定的域名<code>.elasticsearch.logging.svc.cluster.local</code>，接下来我们通过 StatefulSet 来创建具体的 Elasticsearch 的 Pod 应用。</p>

<p>Kubernetes StatefulSet 允许我们为 Pod 分配一个稳定的标识和持久化存储，Elasticsearch 需要稳定的存储来保证 Pod 在重新调度或者重启后的数据依然不变，所以需要使用 StatefulSet 来管理 Pod。</p>

<blockquote>
<p>要了解更多关于 StaefulSet 的信息，可以查看官网关于 StatefulSet 的相关文档：<a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/</a>。</p>
</blockquote>

<p>新建名为 elasticsearch-statefulset.yaml 的资源清单文件，首先粘贴下面内容：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: es-cluster
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: <span style="color:#bd93f9">3</span>
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch</code></pre></div>
<p>该内容中，我们定义了一个名为 es-cluster 的 StatefulSet 对象，然后定义<code>serviceName=elasticsearch</code>和前面创建的 Service 相关联，这可以确保使用以下 DNS 地址访问 StatefulSet 中的每一个 Pod：<code>es-cluster-[0,1,2].elasticsearch.logging.svc.cluster.local</code>，其中[0,1,2]对应于已分配的 Pod 序号。</p>

<p>然后指定3个副本，将 matchLabels 设置为<code>app=elasticsearch</code>，所以 Pod 的模板部分<code>.spec.template.metadata.lables</code>也必须包含<code>app=elasticsearch</code>标签。</p>

<p>然后定义 Pod 模板部分内容：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">...
  spec:
    containers:
    - name: elasticsearch
      image: docker.elastic.co/elasticsearch/elasticsearch-oss:<span style="color:#bd93f9">6.4</span>.<span style="color:#bd93f9">3</span>
      resources:
        limits:
          cpu: 1000m
        requests:
          cpu: 100m
      ports:
      - containerPort: <span style="color:#bd93f9">9200</span>
        name: rest
        protocol: TCP
      - containerPort: <span style="color:#bd93f9">9300</span>
        name: inter-node
        protocol: TCP
      volumeMounts:
      - name: data
        mountPath: /usr/share/elasticsearch/data
      env:
      - name: cluster.name
        value: k8s-logs
      - name: node.name
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: discovery.zen.ping.unicast.hosts
        value: <span style="color:#f1fa8c">&#34;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&#34;</span>
      - name: discovery.zen.minimum_master_nodes
        value: <span style="color:#f1fa8c">&#34;2&#34;</span>
      - name: ES_JAVA_OPTS
        value: <span style="color:#f1fa8c">&#34;-Xms512m -Xmx512m&#34;</span></code></pre></div>
<p>该部分是定义 StatefulSet 中的 Pod，我们这里使用一个<code>-oss</code>后缀的镜像，该镜像是 Elasticsearch 的开源版本，如果你想使用包含<code>X-Pack</code>之类的版本，可以去掉该后缀。然后暴露了9200和9300两个端口，注意名称要和上面定义的 Service 保持一致。然后通过 volumeMount 声明了数据持久化目录，下面我们再来定义 VolumeClaims。最后就是我们在容器中设置的一些环境变量了：</p>

<ul>
<li>cluster.name：Elasticsearch 集群的名称，我们这里命名成 k8s-logs。</li>
<li>node.name：节点的名称，通过<code>metadata.name</code>来获取。这将解析为 es-cluster-[0,1,2]，取决于节点的指定顺序。</li>
<li>discovery.zen.ping.unicast.hosts：此字段用于设置在 Elasticsearch 集群中节点相互连接的发现方法。我们使用 unicastdiscovery 方式，它为我们的集群指定了一个静态主机列表。由于我们之前配置的无头服务，我们的 Pod 具有唯一的 DNS 域<code>es-cluster-[0,1,2].elasticsearch.logging.svc.cluster.local</code>，因此我们相应地设置此变量。由于都在同一个 namespace 下面，所以我们可以将其缩短为<code>es-cluster-[0,1,2].elasticsearch</code>。要了解有关 Elasticsearch 发现的更多信息，请参阅 Elasticsearch 官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html</a>。</li>
<li>discovery.zen.minimum_master_nodes：我们将其设置为<code>(N/2) + 1</code>，<code>N</code>是我们的群集中符合主节点的节点的数量。我们有3个 Elasticsearch 节点，因此我们将此值设置为2（向下舍入到最接近的整数）。要了解有关此参数的更多信息，请参阅官方 Elasticsearch 文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain">https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain</a>。</li>
<li>ES_JAVA_OPTS：这里我们设置为<code>-Xms512m -Xmx512m</code>，告诉<code>JVM</code>使用<code>512 MB</code>的最小和最大堆。您应该根据群集的资源可用性和需求调整这些参数。要了解更多信息，请参阅设置堆大小的相关文档：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html</a>。</li>
</ul>

<p>接下来添加关于 initContainer 的内容：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">...
    initContainers:
    - name: fix-permissions
      image: busybox
      command: [<span style="color:#f1fa8c">&#34;sh&#34;</span>, <span style="color:#f1fa8c">&#34;-c&#34;</span>, <span style="color:#f1fa8c">&#34;chown -R 1000:1000 /usr/share/elasticsearch/data&#34;</span>]
      securityContext:
        privileged: <span style="color:#ff79c6">true</span>
      volumeMounts:
      - name: data
        mountPath: /usr/share/elasticsearch/data
    - name: increase-vm-max-map
      image: busybox
      command: [<span style="color:#f1fa8c">&#34;sysctl&#34;</span>, <span style="color:#f1fa8c">&#34;-w&#34;</span>, <span style="color:#f1fa8c">&#34;vm.max_map_count=262144&#34;</span>]
      securityContext:
        privileged: <span style="color:#ff79c6">true</span>
    - name: increase-fd-ulimit
      image: busybox
      command: [<span style="color:#f1fa8c">&#34;sh&#34;</span>, <span style="color:#f1fa8c">&#34;-c&#34;</span>, <span style="color:#f1fa8c">&#34;ulimit -n 65536&#34;</span>]
      securityContext:
        privileged: <span style="color:#ff79c6">true</span></code></pre></div>
<p>这里我们定义了几个在主应用程序之前运行的 Init 容器，这些初始容器按照定义的顺序依次执行，执行完成后才会启动主应用容器。</p>

<p>第一个名为 fix-permissions 的容器用来运行 chown 命令，将 Elasticsearch 数据目录的用户和组更改为<code>1000:1000</code>（Elasticsearch 用户的 UID）。因为默认情况下，Kubernetes 用 root 用户挂载数据目录，这会使得 Elasticsearch 无法方法该数据目录，可以参考 Elasticsearch 生产中的一些默认注意事项相关文档说明：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults</a>。</p>

<p>第二个名为 increase-vm-max-map 的容器用来增加操作系统对<code>mmap</code>计数的限制，默认情况下该值可能太低，导致内存不足的错误，要了解更多关于该设置的信息，可以查看 Elasticsearch 官方文档说明：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html</a>。</p>

<p>最后一个初始化容器是用来执行<code>ulimit</code>命令增加打开文件描述符的最大数量的。</p>

<blockquote>
<p>此外 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#_notes_for_production_use_and_defaults">Elastisearch Notes for Production Use</a> 文档还提到了由于性能原因最好禁用 swap，当然对于 Kubernetes 集群而言，最好也是禁用 swap 分区的。</p>
</blockquote>

<p>现在我们已经定义了主应用容器和它之前运行的 Init Containers 来调整一些必要的系统参数，接下来我们可以添加数据目录的持久化相关的配置，在 StatefulSet 中，使用 volumeClaimTemplates 来定义 volume 模板即可：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">...
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: elasticsearch
    spec:
      accessModes: [ <span style="color:#f1fa8c">&#34;ReadWriteOnce&#34;</span> ]
      storageClassName: es-data-db
      resources:
        requests:
          storage: 50Gi</code></pre></div>
<p>我们这里使用 volumeClaimTemplates 来定义持久化模板，Kubernetes 会使用它为 Pod 创建 PersistentVolume，设置访问模式为<code>ReadWriteOnce</code>，这意味着它只能被 mount 到单个节点上进行读写，然后最重要的是使用了一个名为 es-data-db 的 StorageClass 对象，所以我们需要提前创建该对象，我们这里使用的 NFS 作为存储后端，所以需要安装一个对应的 provisioner 驱动，前面关于 StorageClass 的课程中已经和大家介绍过方法，新建一个 elasticsearch-storageclass.yaml 的文件，文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: es-data-db
provisioner: fuseim.pri/ifs  <span style="color:#6272a4"># 该值需要和 provisioner 配置的保持一致</span></code></pre></div>
<p>最后，我们指定了每个 PersistentVolume 的大小为 50GB，我们可以根据自己的实际需要进行调整该值。最后，完整的 Elasticsearch StatefulSet 资源清单文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: es-cluster
  namespace: logging
spec:
  serviceName: elasticsearch
  replicas: <span style="color:#bd93f9">3</span>
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch-oss:<span style="color:#bd93f9">6.4</span>.<span style="color:#bd93f9">3</span>
        resources:
            limits:
              cpu: 1000m
            requests:
              cpu: 100m
        ports:
        - containerPort: <span style="color:#bd93f9">9200</span>
          name: rest
          protocol: TCP
        - containerPort: <span style="color:#bd93f9">9300</span>
          name: inter-node
          protocol: TCP
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
        env:
          - name: cluster.name
            value: k8s-logs
          - name: node.name
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: discovery.zen.ping.unicast.hosts
            value: <span style="color:#f1fa8c">&#34;es-cluster-0.elasticsearch,es-cluster-1.elasticsearch,es-cluster-2.elasticsearch&#34;</span>
          - name: discovery.zen.minimum_master_nodes
            value: <span style="color:#f1fa8c">&#34;2&#34;</span>
          - name: ES_JAVA_OPTS
            value: <span style="color:#f1fa8c">&#34;-Xms512m -Xmx512m&#34;</span>
      initContainers:
      - name: fix-permissions
        image: busybox
        command: [<span style="color:#f1fa8c">&#34;sh&#34;</span>, <span style="color:#f1fa8c">&#34;-c&#34;</span>, <span style="color:#f1fa8c">&#34;chown -R 1000:1000 /usr/share/elasticsearch/data&#34;</span>]
        securityContext:
          privileged: <span style="color:#ff79c6">true</span>
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
      - name: increase-vm-max-map
        image: busybox
        command: [<span style="color:#f1fa8c">&#34;sysctl&#34;</span>, <span style="color:#f1fa8c">&#34;-w&#34;</span>, <span style="color:#f1fa8c">&#34;vm.max_map_count=262144&#34;</span>]
        securityContext:
          privileged: <span style="color:#ff79c6">true</span>
      - name: increase-fd-ulimit
        image: busybox
        command: [<span style="color:#f1fa8c">&#34;sh&#34;</span>, <span style="color:#f1fa8c">&#34;-c&#34;</span>, <span style="color:#f1fa8c">&#34;ulimit -n 65536&#34;</span>]
        securityContext:
          privileged: <span style="color:#ff79c6">true</span>
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: elasticsearch
    spec:
      accessModes: [ <span style="color:#f1fa8c">&#34;ReadWriteOnce&#34;</span> ]
      storageClassName: es-data-db
      resources:
        requests:
          storage: 100Gi</code></pre></div>
<p>现在直接使用 kubectl 工具部署即可：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f elasticsearch-storageclass.yaml
storageclass.storage.k8s.io <span style="color:#f1fa8c">&#34;es-data-db&#34;</span> created
$ kubectl create -f elasticsearch-statefulset.yaml
statefulset.apps/es-cluster created</code></pre></div>
<p>添加成功后，可以看到 logging 命名空间下面的所有的资源对象：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get sts -n logging
NAME         DESIRED   CURRENT   AGE
es-cluster   <span style="color:#bd93f9">3</span>         <span style="color:#bd93f9">3</span>         20h
$ kubectl get pods -n logging
NAME                      READY     STATUS    RESTARTS   AGE
es-cluster-0              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
es-cluster-1              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
es-cluster-2              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
$ kubectl get svc -n logging
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>             AGE
elasticsearch   ClusterIP   None             &lt;none&gt;        <span style="color:#bd93f9">9200</span>/TCP,9300/TCP   20h</code></pre></div>
<p>Pods 部署完成后，我们可以通过请求一个 REST API 来检查 Elasticsearch 集群是否正常运行。使用下面的命令将本地端口9200转发到 Elasticsearch 节点（如es-cluster-0）对应的端口：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl port-forward es-cluster-0 <span style="color:#bd93f9">9200</span>:9200 --namespace<span style="color:#ff79c6">=</span>logging
Forwarding from <span style="color:#bd93f9">127</span>.0.0.1:9200 -&gt; <span style="color:#bd93f9">9200</span>
Forwarding from <span style="color:#ff79c6">[</span>::1<span style="color:#ff79c6">]</span>:9200 -&gt; <span style="color:#bd93f9">9200</span></code></pre></div>
<p>然后，在另外的终端窗口中，执行如下请求：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ curl http://localhost:9200/_cluster/state?pretty</code></pre></div>
<p>正常来说，应该会看到类似于如下的信息：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#ff79c6">{</span>
  <span style="color:#f1fa8c">&#34;cluster_name&#34;</span> : <span style="color:#f1fa8c">&#34;k8s-logs&#34;</span>,
  <span style="color:#f1fa8c">&#34;compressed_size_in_bytes&#34;</span> : <span style="color:#bd93f9">348</span>,
  <span style="color:#f1fa8c">&#34;cluster_uuid&#34;</span> : <span style="color:#f1fa8c">&#34;QD06dK7CQgids-GQZooNVw&#34;</span>,
  <span style="color:#f1fa8c">&#34;version&#34;</span> : <span style="color:#bd93f9">3</span>,
  <span style="color:#f1fa8c">&#34;state_uuid&#34;</span> : <span style="color:#f1fa8c">&#34;mjNIWXAzQVuxNNOQ7xR-qg&#34;</span>,
  <span style="color:#f1fa8c">&#34;master_node&#34;</span> : <span style="color:#f1fa8c">&#34;IdM5B7cUQWqFgIHXBp0JDg&#34;</span>,
  <span style="color:#f1fa8c">&#34;blocks&#34;</span> : <span style="color:#ff79c6">{</span> <span style="color:#ff79c6">}</span>,
  <span style="color:#f1fa8c">&#34;nodes&#34;</span> : <span style="color:#ff79c6">{</span>
    <span style="color:#f1fa8c">&#34;u7DoTpMmSCixOoictzHItA&#34;</span> : <span style="color:#ff79c6">{</span>
      <span style="color:#f1fa8c">&#34;name&#34;</span> : <span style="color:#f1fa8c">&#34;es-cluster-1&#34;</span>,
      <span style="color:#f1fa8c">&#34;ephemeral_id&#34;</span> : <span style="color:#f1fa8c">&#34;ZlBflnXKRMC4RvEACHIVdg&#34;</span>,
      <span style="color:#f1fa8c">&#34;transport_address&#34;</span> : <span style="color:#f1fa8c">&#34;10.244.4.191:9300&#34;</span>,
      <span style="color:#f1fa8c">&#34;attributes&#34;</span> : <span style="color:#ff79c6">{</span> <span style="color:#ff79c6">}</span>
    <span style="color:#ff79c6">}</span>,
    <span style="color:#f1fa8c">&#34;IdM5B7cUQWqFgIHXBp0JDg&#34;</span> : <span style="color:#ff79c6">{</span>
      <span style="color:#f1fa8c">&#34;name&#34;</span> : <span style="color:#f1fa8c">&#34;es-cluster-0&#34;</span>,
      <span style="color:#f1fa8c">&#34;ephemeral_id&#34;</span> : <span style="color:#f1fa8c">&#34;JTk1FDdFQuWbSFAtBxdxAQ&#34;</span>,
      <span style="color:#f1fa8c">&#34;transport_address&#34;</span> : <span style="color:#f1fa8c">&#34;10.244.2.215:9300&#34;</span>,
      <span style="color:#f1fa8c">&#34;attributes&#34;</span> : <span style="color:#ff79c6">{</span> <span style="color:#ff79c6">}</span>
    <span style="color:#ff79c6">}</span>,
    <span style="color:#f1fa8c">&#34;R8E7xcSUSbGbgrhAdyAKmQ&#34;</span> : <span style="color:#ff79c6">{</span>
      <span style="color:#f1fa8c">&#34;name&#34;</span> : <span style="color:#f1fa8c">&#34;es-cluster-2&#34;</span>,
      <span style="color:#f1fa8c">&#34;ephemeral_id&#34;</span> : <span style="color:#f1fa8c">&#34;9wv6ke71Qqy9vk2LgJTqaA&#34;</span>,
      <span style="color:#f1fa8c">&#34;transport_address&#34;</span> : <span style="color:#f1fa8c">&#34;10.244.40.4:9300&#34;</span>,
      <span style="color:#f1fa8c">&#34;attributes&#34;</span> : <span style="color:#ff79c6">{</span> <span style="color:#ff79c6">}</span>
    <span style="color:#ff79c6">}</span>
  <span style="color:#ff79c6">}</span>,
...</code></pre></div>
<p>看到上面的信息就表明我们名为 k8s-logs 的 Elasticsearch 集群成功创建了3个节点：es-cluster-0，es-cluster-1，和es-cluster-2，当前主节点是 es-cluster-0。</p>

<h2 id="创建-kibana-服务">创建 Kibana 服务</h2>

<p>Elasticsearch 集群启动成功了，接下来我们可以来部署 Kibana 服务，新建一个名为 kibana.yaml 的文件，对应的文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
spec:
  ports:
  - port: <span style="color:#bd93f9">5601</span>
  type: NodePort
  selector:
    app: kibana

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
  labels:
    app: kibana
spec:
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana-oss:<span style="color:#bd93f9">6.4</span>.<span style="color:#bd93f9">3</span>
        resources:
          limits:
            cpu: 1000m
          requests:
            cpu: 100m
        env:
          - name: ELASTICSEARCH_URL
            value: http://elasticsearch:<span style="color:#bd93f9">9200</span>
        ports:
        - containerPort: <span style="color:#bd93f9">5601</span></code></pre></div>
<p>上面我们定义了两个资源对象，一个 Service 和 Deployment，为了测试方便，我们将 Service 设置为了 NodePort 类型，Kibana Pod 中配置都比较简单，唯一需要注意的是我们使用 ELASTICSEARCH_URL 这个环境变量来设置Elasticsearch 集群的端点和端口，直接使用 Kubernetes DNS 即可，此端点对应服务名称为 elasticsearch，由于是一个 headless service，所以该域将解析为3个 Elasticsearch Pod 的 IP 地址列表。</p>

<p>配置完成后，直接使用 kubectl 工具创建：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f kibana.yaml
service/kibana created
deployment.apps/kibana created</code></pre></div>
<p>创建完成后，可以查看 Kibana Pod 的运行状态：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get pods --namespace<span style="color:#ff79c6">=</span>logging
NAME                      READY     STATUS    RESTARTS   AGE
es-cluster-0              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
es-cluster-1              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
es-cluster-2              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
kibana-7558d4dc4d-5mqdz   <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          20h
$ kubectl get svc --namespace<span style="color:#ff79c6">=</span>logging
NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span style="color:#ff79c6">(</span>S<span style="color:#ff79c6">)</span>             AGE
elasticsearch   ClusterIP   None             &lt;none&gt;        <span style="color:#bd93f9">9200</span>/TCP,9300/TCP   20h
kibana          NodePort    <span style="color:#bd93f9">10</span>.105.208.253   &lt;none&gt;        <span style="color:#bd93f9">5601</span>:31816/TCP      20h</code></pre></div>
<p>如果 Pod 已经是 Running 状态了，证明应用已经部署成功了，然后可以通过 NodePort 来访问 Kibana 这个服务，在浏览器中打开<code>http://&lt;任意节点IP&gt;:31816</code>即可，如果看到如下欢迎界面证明 Kibana 已经成功部署到了 Kubernetes集群之中。</p>

<figure><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fz9h04vmnnj316o0tktdh.jpg" alt="kibana welcome"><figcaption>kibana welcome</figcaption></figure>

<h2 id="部署-fluentd">部署 Fluentd</h2>

<p><code>Fluentd</code> 是一个高效的日志聚合器，是用 Ruby 编写的，并且可以很好地扩展。对于大部分企业来说，Fluentd 足够高效并且消耗的资源相对较少，另外一个工具<code>Fluent-bit</code>更轻量级，占用资源更少，但是插件相对 Fluentd 来说不够丰富，所以整体来说，Fluentd 更加成熟，使用更加广泛，所以我们这里也同样使用 Fluentd 来作为日志收集工具。</p>

<h3 id="工作原理">工作原理</h3>

<p>Fluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过300个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：</p>

<ul>
<li>首先 Fluentd 从多个日志源获取数据</li>
<li>结构化并且标记这些数据</li>
<li>然后根据匹配的标签将数据发送到多个目标服务去</li>
</ul>

<figure><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fz9hctkjysj30xc0ge0tk.jpg" alt="fluentd 架构"><figcaption>fluentd 架构</figcaption></figure>

<h3 id="配置">配置</h3>

<p>一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。</p>

<h4 id="日志源配置">日志源配置</h4>

<p>比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;source&gt;

@id fluentd-containers.log

@type tail

path /var/log/containers/*.log

pos_file /var/log/fluentd-containers.log.pos

time_format %Y-%m-%dT%H:%M:%S.%NZ

tag raw.kubernetes.*

format json

read_from_head true

&lt;/source&gt;</pre></div>
<p>上面配置部分参数说明如下：</p>

<ul>
<li>id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据</li>
<li>type：Fluentd 内置的指令，<code>tail</code>表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是<code>http</code>表示通过一个 GET 请求来收集数据。</li>
<li>path：<code>tail</code>类型下的特定参数，告诉 Fluentd 采集<code>/var/log/containers</code>目录下的所有日志，这是 docker 在 Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。</li>
<li>pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。</li>
<li>tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。</li>
</ul>

<h4 id="路由配置">路由配置</h4>

<p>上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;match **&gt;

@id elasticsearch

@type elasticsearch

@log_level info

include_tag_key true

type_name fluentd

host &#34;#{ENV[&#39;OUTPUT_HOST&#39;]}&#34;

port &#34;#{ENV[&#39;OUTPUT_PORT&#39;]}&#34;

logstash_format true

&lt;buffer&gt;

@type file

path /var/log/fluentd-buffers/kubernetes.system.buffer

flush_mode interval

retry_type exponential_backoff

flush_thread_count 2

flush_interval 5s

retry_forever

retry_max_interval 30

chunk_limit_size &#34;#{ENV[&#39;OUTPUT_BUFFER_CHUNK_LIMIT&#39;]}&#34;

queue_limit_length &#34;#{ENV[&#39;OUTPUT_BUFFER_QUEUE_LIMIT&#39;]}&#34;

overflow_action block

&lt;/buffer&gt;</pre></div>
<ul>
<li>match：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成<code>**</code>。</li>
<li>id：目标的一个唯一标识符。</li>
<li>type：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。</li>
<li>log_level：指定要捕获的日志级别，我们这里配置成<code>info</code>，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elsasticsearch。</li>
<li>host/port：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。</li>
<li>logstash_format：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为<code>true</code>，Fluentd 将会以 logstash 格式来转发结构化的日志数据。</li>
<li>Buffer： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。</li>
</ul>

<h3 id="安装">安装</h3>

<p>要收集 Kubernetes 集群的日志，直接用 DasemonSet 控制器来部署 Fluentd 应用，这样，它就可以从 Kubernetes 节点上采集日志，确保在集群中的每个节点上始终运行一个 Fluentd 容器。当然可以直接使用 Helm 来进行一键安装，为了能够了解更多实现细节，我们这里还是采用手动方法来进行安装。</p>

<p>首先，我们通过 ConfigMap 对象来指定 Fluentd 配置文件，新建 fluentd-configmap.yaml 文件，文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: fluentd-config
  namespace: logging
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
data:
  system.conf: |-
    &lt;system<span style="color:#f1fa8c">&gt;
</span><span style="color:#f1fa8c">      root_dir /tmp/fluentd-buffers/</span>
    &lt;/system<span style="color:#f1fa8c">&gt;
</span><span style="color:#f1fa8c">  containers.input.conf: |-
</span><span style="color:#f1fa8c">    &lt;source&gt;
</span><span style="color:#f1fa8c">      @id fluentd-containers.log
</span><span style="color:#f1fa8c">      @type tail
</span><span style="color:#f1fa8c">      path /var/log/containers/*.log
</span><span style="color:#f1fa8c">      pos_file /var/log/es-containers.log.pos
</span><span style="color:#f1fa8c">      time_format %Y-%m-%dT%H:%M:%S.%NZ
</span><span style="color:#f1fa8c">      localtime
</span><span style="color:#f1fa8c">      tag raw.kubernetes.*
</span><span style="color:#f1fa8c">      format json
</span><span style="color:#f1fa8c">      read_from_head true
</span><span style="color:#f1fa8c">    &lt;/source&gt;
</span><span style="color:#f1fa8c">    # Detect exceptions in the log output and forward them as one log entry.
</span><span style="color:#f1fa8c">    &lt;match raw.kubernetes.**&gt;
</span><span style="color:#f1fa8c">      @id raw.kubernetes
</span><span style="color:#f1fa8c">      @type detect_exceptions
</span><span style="color:#f1fa8c">      remove_tag_prefix raw
</span><span style="color:#f1fa8c">      message log
</span><span style="color:#f1fa8c">      stream stream
</span><span style="color:#f1fa8c">      multiline_flush_interval 5
</span><span style="color:#f1fa8c">      max_bytes 500000
</span><span style="color:#f1fa8c">      max_lines 1000
</span><span style="color:#f1fa8c">    &lt;/match&gt;
</span><span style="color:#f1fa8c">  system.input.conf: |-
</span><span style="color:#f1fa8c">    # Logs from systemd-journal for interesting services.
</span><span style="color:#f1fa8c">    &lt;source&gt;
</span><span style="color:#f1fa8c">      @id journald-docker
</span><span style="color:#f1fa8c">      @type systemd
</span><span style="color:#f1fa8c">      filters [{ &#34;_SYSTEMD_UNIT&#34;: &#34;docker.service&#34; }]
</span><span style="color:#f1fa8c">      &lt;storage&gt;
</span><span style="color:#f1fa8c">        @type local
</span><span style="color:#f1fa8c">        persistent true
</span><span style="color:#f1fa8c">      &lt;/storage&gt;
</span><span style="color:#f1fa8c">      read_from_head true
</span><span style="color:#f1fa8c">      tag docker
</span><span style="color:#f1fa8c">    &lt;/source&gt;
</span><span style="color:#f1fa8c">    &lt;source&gt;
</span><span style="color:#f1fa8c">      @id journald-kubelet
</span><span style="color:#f1fa8c">      @type systemd
</span><span style="color:#f1fa8c">      filters [{ &#34;_SYSTEMD_UNIT&#34;: &#34;kubelet.service&#34; }]
</span><span style="color:#f1fa8c">      &lt;storage&gt;
</span><span style="color:#f1fa8c">        @type local
</span><span style="color:#f1fa8c">        persistent true
</span><span style="color:#f1fa8c">      &lt;/storage&gt;
</span><span style="color:#f1fa8c">      read_from_head true
</span><span style="color:#f1fa8c">      tag kubelet
</span><span style="color:#f1fa8c">    &lt;/source&gt;
</span><span style="color:#f1fa8c">  forward.input.conf: |-
</span><span style="color:#f1fa8c">    # Takes the messages sent over TCP
</span><span style="color:#f1fa8c">    &lt;source&gt;
</span><span style="color:#f1fa8c">      @type forward
</span><span style="color:#f1fa8c">    &lt;/source&gt;
</span><span style="color:#f1fa8c">  output.conf: |-
</span><span style="color:#f1fa8c">    # Enriches records with Kubernetes metadata
</span><span style="color:#f1fa8c">    &lt;filter kubernetes.**&gt;
</span><span style="color:#f1fa8c">      @type kubernetes_metadata
</span><span style="color:#f1fa8c">    &lt;/filter&gt;
</span><span style="color:#f1fa8c">    &lt;match **&gt;
</span><span style="color:#f1fa8c">      @id elasticsearch
</span><span style="color:#f1fa8c">      @type elasticsearch
</span><span style="color:#f1fa8c">      @log_level info
</span><span style="color:#f1fa8c">      include_tag_key true
</span><span style="color:#f1fa8c">      host elasticsearch
</span><span style="color:#f1fa8c">      port 9200
</span><span style="color:#f1fa8c">      logstash_format true
</span><span style="color:#f1fa8c">      request_timeout    30s
</span><span style="color:#f1fa8c">      &lt;buffer&gt;
</span><span style="color:#f1fa8c">        @type file
</span><span style="color:#f1fa8c">        path /var/log/fluentd-buffers/kubernetes.system.buffer
</span><span style="color:#f1fa8c">        flush_mode interval
</span><span style="color:#f1fa8c">        retry_type exponential_backoff
</span><span style="color:#f1fa8c">        flush_thread_count 2
</span><span style="color:#f1fa8c">        flush_interval 5s
</span><span style="color:#f1fa8c">        retry_forever
</span><span style="color:#f1fa8c">        retry_max_interval 30
</span><span style="color:#f1fa8c">        chunk_limit_size 2M
</span><span style="color:#f1fa8c">        queue_limit_length 8
</span><span style="color:#f1fa8c">        overflow_action block
</span><span style="color:#f1fa8c">      &lt;/buffer&gt;
</span><span style="color:#f1fa8c">    &lt;/match&gt;</span></code></pre></div>
<p>上面配置文件中我们配置了 docker 容器日志目录以及 docker、kubelet 应用的日志的收集，收集到数据经过处理后发送到 elasticsearch:9200 服务。</p>

<p>然后新建一个 fluentd-daemonset.yaml 的文件，文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd-es
  namespace: logging
  labels:
    k8s-app: fluentd-es
    kubernetes.io/cluster-service: <span style="color:#f1fa8c">&#34;true&#34;</span>
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd-es
  labels:
    k8s-app: fluentd-es
    kubernetes.io/cluster-service: <span style="color:#f1fa8c">&#34;true&#34;</span>
    addonmanager.kubernetes.io/mode: Reconcile
rules:
- apiGroups:
  - <span style="color:#f1fa8c">&#34;&#34;</span>
  resources:
  - <span style="color:#f1fa8c">&#34;namespaces&#34;</span>
  - <span style="color:#f1fa8c">&#34;pods&#34;</span>
  verbs:
  - <span style="color:#f1fa8c">&#34;get&#34;</span>
  - <span style="color:#f1fa8c">&#34;watch&#34;</span>
  - <span style="color:#f1fa8c">&#34;list&#34;</span>
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd-es
  labels:
    k8s-app: fluentd-es
    kubernetes.io/cluster-service: <span style="color:#f1fa8c">&#34;true&#34;</span>
    addonmanager.kubernetes.io/mode: Reconcile
subjects:
- kind: ServiceAccount
  name: fluentd-es
  namespace: logging
  apiGroup: <span style="color:#f1fa8c">&#34;&#34;</span>
roleRef:
  kind: ClusterRole
  name: fluentd-es
  apiGroup: <span style="color:#f1fa8c">&#34;&#34;</span>
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-es
  namespace: logging
  labels:
    k8s-app: fluentd-es
    version: v2.<span style="color:#bd93f9">0.4</span>
    kubernetes.io/cluster-service: <span style="color:#f1fa8c">&#34;true&#34;</span>
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-es
      version: v2.<span style="color:#bd93f9">0.4</span>
  template:
    metadata:
      labels:
        k8s-app: fluentd-es
        kubernetes.io/cluster-service: <span style="color:#f1fa8c">&#34;true&#34;</span>
        version: v2.<span style="color:#bd93f9">0.4</span>
      <span style="color:#6272a4"># This annotation ensures that fluentd does not get evicted if the node</span>
      <span style="color:#6272a4"># supports critical pod annotation based priority scheme.</span>
      <span style="color:#6272a4"># Note that this does not guarantee admission on the nodes (#40573).</span>
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: <span style="color:#f1fa8c">&#39;&#39;</span>
    spec:
      priorityClassName: system-node-critical
      serviceAccountName: fluentd-es
      containers:
      - name: fluentd-es
        image: cnych/fluentd-elasticsearch:v2.<span style="color:#bd93f9">0.4</span>
        env:
        - name: FLUENTD_ARGS
          value: --no-supervisor -q
        resources:
          limits:
            memory: 500Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /data/docker/containers
          readOnly: <span style="color:#ff79c6">true</span>
        - name: config-volume
          mountPath: /etc/fluent/config.d
      nodeSelector:
        beta.kubernetes.io/fluentd-ds-ready: <span style="color:#f1fa8c">&#34;true&#34;</span>
      tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      terminationGracePeriodSeconds: <span style="color:#bd93f9">30</span>
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /data/docker/containers
      - name: config-volume
        configMap:
          name: fluentd-config</code></pre></div>
<p>我们将上面创建的 fluentd-config 这个 ConfigMap 对象通过 volumes 挂载到了 Fluentd 容器中，另外为了能够灵活控制哪些节点的日志可以被收集，所以我们这里还添加了一个 nodSelector 属性：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">nodeSelector:
  beta.kubernetes.io/fluentd-ds-ready: <span style="color:#f1fa8c">&#34;true&#34;</span></code></pre></div>
<p>意思就是要想采集节点的日志，那么我们就需要给节点打上上面的标签，比如我们这里3个节点都打上了该标签：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get nodes --show-labels
NAME      STATUS    ROLES     AGE       VERSION   LABELS
master    Ready     master    245d      v1.10.0   beta.kubernetes.io/arch<span style="color:#ff79c6">=</span>amd64,beta.kubernetes.io/fluentd-ds-ready<span style="color:#ff79c6">=</span>true,beta.kubernetes.io/os<span style="color:#ff79c6">=</span>linux,kubernetes.io/hostname<span style="color:#ff79c6">=</span>master,node-role.kubernetes.io/master<span style="color:#ff79c6">=</span>
node02    Ready     &lt;none&gt;    165d      v1.10.0   beta.kubernetes.io/arch<span style="color:#ff79c6">=</span>amd64,beta.kubernetes.io/fluentd-ds-ready<span style="color:#ff79c6">=</span>true,beta.kubernetes.io/os<span style="color:#ff79c6">=</span>linux,com<span style="color:#ff79c6">=</span>youdianzhishi,course<span style="color:#ff79c6">=</span>k8s,kubernetes.io/hostname<span style="color:#ff79c6">=</span>node02
node03    Ready     &lt;none&gt;    225d      v1.10.0   beta.kubernetes.io/arch<span style="color:#ff79c6">=</span>amd64,beta.kubernetes.io/fluentd-ds-ready<span style="color:#ff79c6">=</span>true,beta.kubernetes.io/os<span style="color:#ff79c6">=</span>linux,jnlp<span style="color:#ff79c6">=</span>haimaxy,kubernetes.io/hostname<span style="color:#ff79c6">=</span>node03</code></pre></div>
<p>另外由于我们的集群使用的是 kubeadm 搭建的，默认情况下 master 节点有污点，所以要想也收集 master 节点的日志，则需要添加上容忍：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">tolerations:
- key: node-role.kubernetes.io/master
  operator: Exists
  effect: NoSchedule</code></pre></div>
<p>另外需要注意的地方是，我这里的测试环境更改了 docker 的根目录：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ docker info
...
Docker Root Dir: /data/docker
...</code></pre></div>
<p>所以上面要获取 docker 的容器目录需要更改成<code>/data/docker/containers</code>，这个地方非常重要，当然如果你没有更改 docker 根目录则使用默认的<code>/var/lib/docker/containers</code>目录即可。</p>

<p>分别创建上面的 ConfigMap 对象和 DaemonSet：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f fluentd-configmap.yaml
configmap <span style="color:#f1fa8c">&#34;fluentd-config&#34;</span> created
$ kubectl create -f fluentd-daemonset.yaml
serviceaccount <span style="color:#f1fa8c">&#34;fluentd-es&#34;</span> created
clusterrole.rbac.authorization.k8s.io <span style="color:#f1fa8c">&#34;fluentd-es&#34;</span> created
clusterrolebinding.rbac.authorization.k8s.io <span style="color:#f1fa8c">&#34;fluentd-es&#34;</span> created
daemonset.apps <span style="color:#f1fa8c">&#34;fluentd-es&#34;</span> created</code></pre></div>
<p>创建完成后，查看对应的 Pods 列表，检查是否部署成功：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl get pods -n logging
NAME                      READY     STATUS    RESTARTS   AGE
es-cluster-0              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          1d
es-cluster-1              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          1d
es-cluster-2              <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          1d
fluentd-es-2z9jg          <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">1</span>          35s
fluentd-es-6dfdd          <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          35s
fluentd-es-bfkg7          <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          35s
kibana-7558d4dc4d-5mqdz   <span style="color:#bd93f9">1</span>/1       Running   <span style="color:#bd93f9">0</span>          1d</code></pre></div>
<p>Fluentd 启动成功后，我们可以前往 Kibana 的 Dashboard 页面中，点击左侧的<code>Discover</code>，可以看到如下配置页面：</p>

<figure><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fz9nkcfrrrj31cf0u00y2.jpg" alt="create index"><figcaption>create index</figcaption></figure>

<p>在这里可以配置我们需要的 Elasticsearch 索引，前面 Fluentd 配置文件中我们采集的日志使用的是 logstash 格式，这里只需要在文本框中输入<code>logstash-*</code>即可匹配到 Elasticsearch 集群中的所有日志数据，然后点击下一步，进入以下页面：</p>

<figure><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fz9noes54aj31di0u043y.jpg" alt="index config"><figcaption>index config</figcaption></figure>

<p>在该页面中配置使用哪个字段按时间过滤日志数据，在下拉列表中，选择<code>@timestamp</code>字段，然后点击<code>Create index pattern</code>，创建完成后，点击左侧导航菜单中的<code>Discover</code>，然后就可以看到一些直方图和最近采集到的日志数据了：</p>

<figure><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fz9ntqiplvj31df0u04bf.jpg" alt="log data"><figcaption>log data</figcaption></figure>

<h3 id="测试">测试</h3>

<p>现在我们来将上一节课的计数器应用部署到集群中，并在 Kibana 中来查找该日志数据。</p>

<p>新建 counter.yaml 文件，文件内容如下：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args: [/bin/sh, -c,
            <span style="color:#f1fa8c">&#39;i=0; while true; do echo &#34;$i: $(date)&#34;; i=$((i+1)); sleep 1; done&#39;</span>]</code></pre></div>
<p>该 Pod 只是简单将日志信息打印到 stdout，所以正常来说 Fluentd 会收集到这个日志数据，在 Kibana 中也就可以找到对应的日志数据了，使用 kubectl 工具创建该 Pod：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">$ kubectl create -f counter.yaml</code></pre></div>
<p>Pod 创建并运行后，回到 Kibana Dashboard 页面，在上面的<code>Discover</code>页面搜索栏中输入<code>kubernetes.pod_name:counter</code>，就可以过滤 Pod 名为 counter 的日志数据：</p>

<figure><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fz9o3c5ds8j31df0u0qg5.jpg" alt="counter log data"><figcaption>counter log data</figcaption></figure>

<p>我们也可以通过其他元数据来过滤日志数据，比如
您可以单击任何日志条目以查看其他元数据，如容器名称，Kubernetes 节点，命名空间等。</p>

<p>到这里，我们就在 Kubernetes 集群上成功部署了 EFK ，要了解如何使用 Kibana 进行日志数据分析，可以参考 Kibana 用户指南文档：<a href="https://www.elastic.co/guide/en/kibana/current/index.html">https://www.elastic.co/guide/en/kibana/current/index.html</a></p>

<p>当然对于在生产环境上使用 Elaticsearch 或者 Fluentd，还需要结合实际的环境做一系列的优化工作，本文中涉及到的资源清单文件都可以在<a href="https://github.com/cnych/kubernetes-learning/tree/master/efkdemo">https://github.com/cnych/kubernetes-learning/tree/master/efkdemo</a>找到。</p>

<blockquote>
<p>参考文档: <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-elasticsearch-fluentd-and-kibana-efk-logging-stack-on-kubernetes">How To Set Up an Elasticsearch, Fluentd and Kibana (EFK) Logging Stack on Kubernetes</a></p>
</blockquote>

<h2 id="推广">推广</h2>

<p>最后打个广告，给大家推荐一个本人精心打造的一个精品课程，现在限时优惠中：<a href="https://youdianzhishi.com/course/6n8xd6/">从 Docker 到 Kubernetes 进阶</a>
<a href="https://youdianzhishi.com/course/6n8xd6/"><img src="http://sdn.haimaxy.com/covers/2018/4/21/c4082e0f09c746aa848279a2567cffed.png" alt="从 Docker 到 Kubernetes 进阶" /></a></p>

<p>扫描下面的二维码(或微信搜索<code>k8s技术圈</code>)关注我们的微信公众帐号，在微信公众帐号中回复 <strong>加群</strong> 即可加入到我们的 kubernetes 讨论群里面共同学习。
<img src="https://www.qikqiak.com/img/posts/qrcode_for_gh_d6dd87b6ceb4_430.jpg" alt="qrcode" /></p>

        
          <div class="entry-shang text-center">
    <p>「真诚赞赏，手留余香」</p>
    <button class="zs show-zs btn btn-bred">赞赏</button>
</div>
<div class="zs-modal-bg"></div>
<div class="zs-modal-box">
    <div class="zs-modal-head">
        <button type="button" class="close">×</button>
        <span class="author"><img src="https://www.qikqiak.com/img/avatar.jpeg"/>阳明</span>
        <p class="tip"><i></i><span>请我喝杯咖啡？</span></p>
    </div>
    <div class="zs-modal-body">
        <div class="zs-modal-btns">
            <button class="btn btn-blink" data-num="2">2元</button>
            <button class="btn btn-blink" data-num="5">5元</button>
            <button class="btn btn-blink" data-num="10">10元</button>
            <button class="btn btn-blink" data-num="50">50元</button>
            <button class="btn btn-blink" data-num="100">100元</button>
            <button class="btn btn-blink" data-num="1">任意金额</button>
        </div>
        <div class="zs-modal-pay">
            <button class="btn btn-bred" id="pay-text">2元</button>
            <p>使用<span id="pay-type">微信</span>扫描二维码完成支付</p>
            <img src="https://www.qikqiak.com/img/wechat-2.png" id="pay-image"/>
        </div>
    </div>
    <div class="zs-modal-footer">
        <span class="zs-wechat"><img src="https://www.qikqiak.com/img/wechat-btn.png"/></span>
    </div>
</div>
        
        
          <div class="social-share" data-initialized="true" style="margin-bottom: 20px;margin-top:20px;">
    <center>
    <a href="#" class="social-share-icon icon-weibo"></a>
    <a href="#" class="social-share-icon icon-wechat"></a>
    <a href="#" class="social-share-icon icon-twitter"></a>
    <a href="#" class="social-share-icon icon-linkedin"></a>
    <a href="#" class="social-share-icon icon-facebook"></a>
    <a href="#" class="social-share-icon icon-qq"></a>
    <a href="#" class="social-share-icon icon-qzone"></a>
    </center>
</div>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>

        
      </article>

      
        

<h3>相关文章</h3>
<ul style="margin-bottom: 25px;">
    
    <li><a href="https://www.qikqiak.com/post/kubernetes-logs-architecture/">kubernetes 日志架构</a></li>
    
    <li><a href="https://www.qikqiak.com/post/kubernetes-logs-collect/">kubernetes 日志收集方案</a></li>
    
    <li><a href="https://www.qikqiak.com/post/k8s-cka-course/">Kubernetes CKA 实训免费视频课程</a></li>
    
    <li><a href="https://www.qikqiak.com/post/office-env-k8s-network/">办公环境下 kubernetes 网络互通方案</a></li>
    
    <li><a href="https://www.qikqiak.com/post/shengdan-promotion/">圣诞元旦课程优惠活动</a></li>
    
    <li><a href="https://www.qikqiak.com/post/prometheus-operator-advance/">Prometheus Operator 高级配置</a></li>
    
    <li><a href="https://www.qikqiak.com/post/prometheus-operator-custom-alert/">Prometheus Operator 自定义报警</a></li>
    
    <li><a href="https://www.qikqiak.com/post/prometheus-operator-monitor-etcd/">Prometheus Operator 监控 etcd 集群</a></li>
    
    <li><a href="https://www.qikqiak.com/post/grafana-log-tool-loki/">Grafana 日志聚合工具 Loki</a></li>
    
    <li><a href="https://www.qikqiak.com/post/first-use-prometheus-operator/">Prometheus Operator 初体验</a></li>
    
</ul>

      

      
      <ul class="pager blog-pager">
        
          <li class="previous">
            <a href="https://www.qikqiak.com/post/k8s-cka-course/" data-toggle="tooltip" data-placement="top" title="Kubernetes CKA 实训免费视频课程">&larr; 前一篇</a>
          </li>
        
        
          <li class="next">
            <a href="https://www.qikqiak.com/post/k8s-istio-course/" data-toggle="tooltip" data-placement="top" title="Istio 实训免费视频课程">后一篇 &rarr;</a>
          </li>
        
      </ul>
      

      

      
      <div id="git-comments"></div>
      <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
      <script src="https://www.qikqiak.com/js/gitment.browser.js"></script>
      <script>
      var gitment = new Gitment({
        id: 'install-efk-stack-on-k8s',
        title: '在 Kubernetes 上搭建 EFK 日志收集系统',
        owner: 'cnych',
        repo: 'blog',
        oauth: {
          client_id: 'bdb76dbb2e9d0786e350',
          client_secret: 'b454b2a08013fd0e32013be7a63fa8fcb262b6c4',
        }
      })
      gitment.render('git-comments')
      </script>
      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          <img src="https://www.qikqiak.com/img/wechatmp.png">
          
              <li>
                <a href="mailto:icnych@gmail.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
              <li>
                <a href="https://github.com/cnych" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
              <li>
                <a href="https://weibo.com/cnych" title="微博">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
              <li>
                <a href="https://instagram.com/cnych" title="Instagram">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-instagram fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          
          <li>
            <a href="https://www.qikqiak.com/index.xml" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;
          2019

          
            &nbsp;&bull;&nbsp;
            <a href="https://www.qikqiak.com/">阳明的博客</a>
            &nbsp;&bull;&nbsp;
            <a href="https://www.qikqiak.com/sitemap.xml">网站地图</a>
            &nbsp;&bull;&nbsp;
            <a href="https://www.qikqiak.com/archives/">文章归档</a>
            <a class="h" href="https://www.qikqiak.com/page/kubernetes.io">kubernetes.io</a>
            <a class="h" href="https://www.qikqiak.com/page/kubernetes.org.cn">Kubernetes中文社区</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          由 <a href="http://gohugo.io">Hugo v0.53</a> 强力驱动 &nbsp;&bull;&nbsp; 主题 <a href="https://github.com/cnych/qikqiak.com">qikqiak-blog</a> 移植自 <a href="https://github.com/rootsongjc/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>



<script src='https://www.qikqiak.com/js/bundle.min.e9a661cbb9d1fc6bdfe60c959774b58baab7e60424854304fd736cd5ab6a9c4d.js' integrity='sha256-6aZhy7nR/Gvf5gyVl3S1i6q35gQkhUME/XNs1atqnE0='></script>




<script async src="https://www.googletagmanager.com/gtag/js?id=UA-69668147-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-69668147-3');
</script>
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

  </body>
</html>

